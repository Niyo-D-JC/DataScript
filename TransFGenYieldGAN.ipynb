{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "E4SPUVamfWqj",
        "Wj1SY91Tfhcu",
        "MfXr02mmmMnE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Import"
      ],
      "metadata": {
        "id": "yiMfxCOvrxLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install rdt\n",
        "! pip install pot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NF2qZI0dOf4",
        "outputId": "945045df-9f50-4620-e517-d14d7c7e7662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdt\n",
            "  Downloading rdt-1.9.1-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.9/74.9 kB\u001b[0m \u001b[31m599.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Faker<20,>=17 (from rdt)\n",
            "  Downloading Faker-19.13.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1.23.3 in /usr/local/lib/python3.10/dist-packages (from rdt) (1.23.5)\n",
            "Requirement already satisfied: scipy<2,>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from rdt) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from rdt) (1.2.2)\n",
            "Requirement already satisfied: pandas>=1.3.4 in /usr/local/lib/python3.10/dist-packages (from rdt) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from Faker<20,>=17->rdt) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.4->rdt) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2,>=1.1.3->rdt) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2,>=1.1.3->rdt) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->Faker<20,>=17->rdt) (1.16.0)\n",
            "Installing collected packages: Faker, rdt\n",
            "Successfully installed Faker-19.13.0 rdt-1.9.1\n",
            "Collecting pot\n",
            "  Downloading POT-0.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.0/823.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from pot) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.10/dist-packages (from pot) (1.11.4)\n",
            "Installing collected packages: pot\n",
            "Successfully installed pot-0.9.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ev0JuhdYq_fC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "from torch import nn\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.nn import BatchNorm1d, Dropout, LeakyReLU, Linear, Module, ReLU, Sequential, functional\n",
        "from tqdm import tqdm\n",
        "\n",
        "import contextlib\n",
        "from collections import namedtuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "from rdt.transformers import ClusterBasedNormalizer, OneHotEncoder\n",
        "from scipy.stats import ks_2samp, anderson_ksamp\n",
        "import ot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data"
      ],
      "metadata": {
        "id": "4PLveQClr6y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymZPiVlEr89t",
        "outputId": "9013b4ae-2f02-4518-a542-4e50e42d06d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"/content/drive/MyDrive/GenHack3/data/\"\n",
        "S1 = pd.read_csv(dir + \"station_49.csv\")\n",
        "S2 = pd.read_csv(dir + \"station_80.csv\")\n",
        "S3 = pd.read_csv(dir + \"station_40.csv\")\n",
        "S4 = pd.read_csv(dir + \"station_63.csv\")\n",
        "noise = np.load(dir + \"noise.npy\")"
      ],
      "metadata": {
        "id": "52FbLYWZsHDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S1.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "1jKn591utMuJ",
        "outputId": "347277ed-4f13-44e7-c4a9-f882aec4ec72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   YEAR        W_1        W_2        W_3        W_4        W_5        W_6  \\\n",
              "0     0  20.487164  26.089329  25.394672  27.024097  24.426756  26.420241   \n",
              "1     1  21.430837  22.228488  24.205256  29.859199  30.434175  26.467017   \n",
              "\n",
              "         W_7        W_8        W_9      W_10      W_11      W_12      W_13  \\\n",
              "0  25.534358  21.369482  18.577526  1.384519  1.401463  0.862322  1.536162   \n",
              "1  27.300290  22.509277  16.388211  1.237347  1.467149  1.357827  0.875649   \n",
              "\n",
              "       W_14      W_15      W_16      W_17      W_18  YIELD  \n",
              "0  1.640605  0.204141  1.078367  1.379353  0.886892   6.37  \n",
              "1  0.305032  1.673852  0.214576  0.533683  1.496904   5.54  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe6b8491-5c82-48ae-a341-d0596832dd24\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>W_1</th>\n",
              "      <th>W_2</th>\n",
              "      <th>W_3</th>\n",
              "      <th>W_4</th>\n",
              "      <th>W_5</th>\n",
              "      <th>W_6</th>\n",
              "      <th>W_7</th>\n",
              "      <th>W_8</th>\n",
              "      <th>W_9</th>\n",
              "      <th>W_10</th>\n",
              "      <th>W_11</th>\n",
              "      <th>W_12</th>\n",
              "      <th>W_13</th>\n",
              "      <th>W_14</th>\n",
              "      <th>W_15</th>\n",
              "      <th>W_16</th>\n",
              "      <th>W_17</th>\n",
              "      <th>W_18</th>\n",
              "      <th>YIELD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>20.487164</td>\n",
              "      <td>26.089329</td>\n",
              "      <td>25.394672</td>\n",
              "      <td>27.024097</td>\n",
              "      <td>24.426756</td>\n",
              "      <td>26.420241</td>\n",
              "      <td>25.534358</td>\n",
              "      <td>21.369482</td>\n",
              "      <td>18.577526</td>\n",
              "      <td>1.384519</td>\n",
              "      <td>1.401463</td>\n",
              "      <td>0.862322</td>\n",
              "      <td>1.536162</td>\n",
              "      <td>1.640605</td>\n",
              "      <td>0.204141</td>\n",
              "      <td>1.078367</td>\n",
              "      <td>1.379353</td>\n",
              "      <td>0.886892</td>\n",
              "      <td>6.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>21.430837</td>\n",
              "      <td>22.228488</td>\n",
              "      <td>24.205256</td>\n",
              "      <td>29.859199</td>\n",
              "      <td>30.434175</td>\n",
              "      <td>26.467017</td>\n",
              "      <td>27.300290</td>\n",
              "      <td>22.509277</td>\n",
              "      <td>16.388211</td>\n",
              "      <td>1.237347</td>\n",
              "      <td>1.467149</td>\n",
              "      <td>1.357827</td>\n",
              "      <td>0.875649</td>\n",
              "      <td>0.305032</td>\n",
              "      <td>1.673852</td>\n",
              "      <td>0.214576</td>\n",
              "      <td>0.533683</td>\n",
              "      <td>1.496904</td>\n",
              "      <td>5.54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe6b8491-5c82-48ae-a341-d0596832dd24')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fe6b8491-5c82-48ae-a341-d0596832dd24 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fe6b8491-5c82-48ae-a341-d0596832dd24');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-da55c57b-0f37-4ecd-8956-4065ff228e66\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-da55c57b-0f37-4ecd-8956-4065ff228e66')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-da55c57b-0f37-4ecd-8956-4065ff228e66 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn_R_1eStUG5",
        "outputId": "a0e4f5c1-ba36-4537-dc46-500704aa4645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(S1.shape == S2.shape) and (S3.shape == S4.shape) and (S1.shape == S3.shape) and (S3.shape == (10000, 20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo-lFyd7tkKB",
        "outputId": "f3ac1452-7720-4ffe-b623-7a23a15aa78e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "S1.columns = [f'S1_{col}' for col in S1.columns]\n",
        "S2.columns = [f'S2_{col}' for col in S2.columns]\n",
        "S3.columns = [f'S3_{col}' for col in S3.columns]\n",
        "S4.columns = [f'S4_{col}' for col in S4.columns]\n",
        "\n",
        "data_use = pd.concat([S1, S2, S3, S4], axis=1)\n",
        "\n",
        "data_use.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "RNRzCoZCuyt5",
        "outputId": "3c3cd46f-77cc-4d27-9030-c720316c828b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   S1_YEAR     S1_W_1     S1_W_2     S1_W_3     S1_W_4     S1_W_5     S1_W_6  \\\n",
              "0        0  20.487164  26.089329  25.394672  27.024097  24.426756  26.420241   \n",
              "1        1  21.430837  22.228488  24.205256  29.859199  30.434175  26.467017   \n",
              "2        2  18.841767  25.165941  24.169267  28.742330  27.342035  27.945379   \n",
              "3        3  18.359661  20.235180  22.714217  30.017206  27.192345  23.159092   \n",
              "4        4  21.125963  23.270596  22.949896  26.594044  31.557704  28.464610   \n",
              "\n",
              "      S1_W_7     S1_W_8     S1_W_9  ...   S4_W_10   S4_W_11   S4_W_12  \\\n",
              "0  25.534358  21.369482  18.577526  ...  1.462204  3.951453  2.101091   \n",
              "1  27.300290  22.509277  16.388211  ...  1.036085  0.879651  5.583977   \n",
              "2  25.710641  22.343698  19.797961  ...  3.295700  2.556876  2.165009   \n",
              "3  23.287619  19.477149  18.917730  ...  2.872424  3.686682  4.716563   \n",
              "4  27.306957  26.999664  16.666535  ...  2.240781  2.920387  1.472874   \n",
              "\n",
              "    S4_W_13   S4_W_14   S4_W_15   S4_W_16   S4_W_17   S4_W_18  S4_YIELD  \n",
              "0  1.141454  2.167033  7.972668  1.555216  6.219460  2.081787      5.97  \n",
              "1  0.319974  1.612761  3.304209  0.060819  1.540583  3.214933      5.77  \n",
              "2  2.165768  1.791010  3.012968  4.316012  2.021236  0.814444      8.65  \n",
              "3  2.837129  0.638416  2.147741  3.114913  1.106072  0.870118      1.07  \n",
              "4  1.235341  3.050564  0.899664  1.561179  0.975300  3.242242      7.40  \n",
              "\n",
              "[5 rows x 80 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34b4031f-30a1-496a-9769-ff79e461a6a7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S1_YEAR</th>\n",
              "      <th>S1_W_1</th>\n",
              "      <th>S1_W_2</th>\n",
              "      <th>S1_W_3</th>\n",
              "      <th>S1_W_4</th>\n",
              "      <th>S1_W_5</th>\n",
              "      <th>S1_W_6</th>\n",
              "      <th>S1_W_7</th>\n",
              "      <th>S1_W_8</th>\n",
              "      <th>S1_W_9</th>\n",
              "      <th>...</th>\n",
              "      <th>S4_W_10</th>\n",
              "      <th>S4_W_11</th>\n",
              "      <th>S4_W_12</th>\n",
              "      <th>S4_W_13</th>\n",
              "      <th>S4_W_14</th>\n",
              "      <th>S4_W_15</th>\n",
              "      <th>S4_W_16</th>\n",
              "      <th>S4_W_17</th>\n",
              "      <th>S4_W_18</th>\n",
              "      <th>S4_YIELD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>20.487164</td>\n",
              "      <td>26.089329</td>\n",
              "      <td>25.394672</td>\n",
              "      <td>27.024097</td>\n",
              "      <td>24.426756</td>\n",
              "      <td>26.420241</td>\n",
              "      <td>25.534358</td>\n",
              "      <td>21.369482</td>\n",
              "      <td>18.577526</td>\n",
              "      <td>...</td>\n",
              "      <td>1.462204</td>\n",
              "      <td>3.951453</td>\n",
              "      <td>2.101091</td>\n",
              "      <td>1.141454</td>\n",
              "      <td>2.167033</td>\n",
              "      <td>7.972668</td>\n",
              "      <td>1.555216</td>\n",
              "      <td>6.219460</td>\n",
              "      <td>2.081787</td>\n",
              "      <td>5.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>21.430837</td>\n",
              "      <td>22.228488</td>\n",
              "      <td>24.205256</td>\n",
              "      <td>29.859199</td>\n",
              "      <td>30.434175</td>\n",
              "      <td>26.467017</td>\n",
              "      <td>27.300290</td>\n",
              "      <td>22.509277</td>\n",
              "      <td>16.388211</td>\n",
              "      <td>...</td>\n",
              "      <td>1.036085</td>\n",
              "      <td>0.879651</td>\n",
              "      <td>5.583977</td>\n",
              "      <td>0.319974</td>\n",
              "      <td>1.612761</td>\n",
              "      <td>3.304209</td>\n",
              "      <td>0.060819</td>\n",
              "      <td>1.540583</td>\n",
              "      <td>3.214933</td>\n",
              "      <td>5.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>18.841767</td>\n",
              "      <td>25.165941</td>\n",
              "      <td>24.169267</td>\n",
              "      <td>28.742330</td>\n",
              "      <td>27.342035</td>\n",
              "      <td>27.945379</td>\n",
              "      <td>25.710641</td>\n",
              "      <td>22.343698</td>\n",
              "      <td>19.797961</td>\n",
              "      <td>...</td>\n",
              "      <td>3.295700</td>\n",
              "      <td>2.556876</td>\n",
              "      <td>2.165009</td>\n",
              "      <td>2.165768</td>\n",
              "      <td>1.791010</td>\n",
              "      <td>3.012968</td>\n",
              "      <td>4.316012</td>\n",
              "      <td>2.021236</td>\n",
              "      <td>0.814444</td>\n",
              "      <td>8.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>18.359661</td>\n",
              "      <td>20.235180</td>\n",
              "      <td>22.714217</td>\n",
              "      <td>30.017206</td>\n",
              "      <td>27.192345</td>\n",
              "      <td>23.159092</td>\n",
              "      <td>23.287619</td>\n",
              "      <td>19.477149</td>\n",
              "      <td>18.917730</td>\n",
              "      <td>...</td>\n",
              "      <td>2.872424</td>\n",
              "      <td>3.686682</td>\n",
              "      <td>4.716563</td>\n",
              "      <td>2.837129</td>\n",
              "      <td>0.638416</td>\n",
              "      <td>2.147741</td>\n",
              "      <td>3.114913</td>\n",
              "      <td>1.106072</td>\n",
              "      <td>0.870118</td>\n",
              "      <td>1.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>21.125963</td>\n",
              "      <td>23.270596</td>\n",
              "      <td>22.949896</td>\n",
              "      <td>26.594044</td>\n",
              "      <td>31.557704</td>\n",
              "      <td>28.464610</td>\n",
              "      <td>27.306957</td>\n",
              "      <td>26.999664</td>\n",
              "      <td>16.666535</td>\n",
              "      <td>...</td>\n",
              "      <td>2.240781</td>\n",
              "      <td>2.920387</td>\n",
              "      <td>1.472874</td>\n",
              "      <td>1.235341</td>\n",
              "      <td>3.050564</td>\n",
              "      <td>0.899664</td>\n",
              "      <td>1.561179</td>\n",
              "      <td>0.975300</td>\n",
              "      <td>3.242242</td>\n",
              "      <td>7.40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 80 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34b4031f-30a1-496a-9769-ff79e461a6a7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-34b4031f-30a1-496a-9769-ff79e461a6a7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-34b4031f-30a1-496a-9769-ff79e461a6a7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aaf7568a-dfb0-4caf-8453-ca3b6b9a4de6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aaf7568a-dfb0-4caf-8453-ca3b6b9a4de6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aaf7568a-dfb0-4caf-8453-ca3b6b9a4de6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_keep = [col for col in data_use.columns if \"YEAR\" not in col]\n",
        "data_use = data_use[columns_to_keep]"
      ],
      "metadata": {
        "id": "xh9nLOXEvLAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q1, Q2, Q3, Q4 = 3.3241, 5.1292, 6.4897, 7.1301\n",
        "conditions = (\n",
        "    (data_use.S1_W_13 + data_use.S1_W_14 + data_use.S1_W_15 <= Q1) &\n",
        "     (data_use.S2_W_13 + data_use.S2_W_14 + data_use.S2_W_15 <= Q2) &\n",
        "      (data_use.S3_W_13 + data_use.S3_W_14 + data_use.S3_W_15 <= Q3) &\n",
        "       (data_use.S4_W_13 + data_use.S4_W_14 + data_use.S4_W_15 <= Q4)\n",
        ")\n",
        "\n",
        "data_use['condition'] = np.where(conditions, 'Oui', 'Non')"
      ],
      "metadata": {
        "id": "Lgp8e2xKxH7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_interest = data_use[data_use.condition == 'Oui']"
      ],
      "metadata": {
        "id": "oL2iXRZGuQ-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_interest.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y5iXjlJwq-V",
        "outputId": "c5c2eec4-2fa3-4122-c4db-c8023f10968e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 77)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_interest.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "_2Mio2yDjrFc",
        "outputId": "8430e119-7f2b-4a30-e17c-4aaf1815294b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       S1_W_1     S1_W_2     S1_W_3     S1_W_4     S1_W_5     S1_W_6  \\\n",
              "1   21.430837  22.228488  24.205256  29.859199  30.434175  26.467017   \n",
              "2   18.841767  25.165941  24.169267  28.742330  27.342035  27.945379   \n",
              "10  23.067487  21.989987  26.730305  27.207224  28.277049  26.121537   \n",
              "28  24.441997  24.273763  23.400111  27.344886  25.011067  28.047828   \n",
              "33  21.562630  22.283709  25.263382  25.713687  28.258033  28.984649   \n",
              "\n",
              "       S1_W_7     S1_W_8     S1_W_9   S1_W_10  ...   S4_W_11   S4_W_12  \\\n",
              "1   27.300290  22.509277  16.388211  1.237347  ...  0.879651  5.583977   \n",
              "2   25.710641  22.343698  19.797961  2.509957  ...  2.556876  2.165009   \n",
              "10  30.583426  22.363784  15.826520  1.832929  ...  2.468359  0.930159   \n",
              "28  25.841452  20.996116  16.747943  0.877913  ...  1.782715  3.127549   \n",
              "33  26.601343  23.831066  17.453389  1.081927  ...  5.300191  0.870621   \n",
              "\n",
              "     S4_W_13   S4_W_14   S4_W_15   S4_W_16   S4_W_17   S4_W_18  S4_YIELD  \\\n",
              "1   0.319974  1.612761  3.304209  0.060819  1.540583  3.214933      5.77   \n",
              "2   2.165768  1.791010  3.012968  4.316012  2.021236  0.814444      8.65   \n",
              "10  1.402261  2.402111  2.140366  1.821273  1.763787  4.698325      6.34   \n",
              "28  0.520928  1.781335  2.064324  2.425123  3.876324  1.230727      3.93   \n",
              "33  0.466796  0.665607  2.231320  2.971977  1.737167  3.273389      5.58   \n",
              "\n",
              "    condition  \n",
              "1         Oui  \n",
              "2         Oui  \n",
              "10        Oui  \n",
              "28        Oui  \n",
              "33        Oui  \n",
              "\n",
              "[5 rows x 77 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0e9295d-9b39-410d-8d01-6638731146cc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S1_W_1</th>\n",
              "      <th>S1_W_2</th>\n",
              "      <th>S1_W_3</th>\n",
              "      <th>S1_W_4</th>\n",
              "      <th>S1_W_5</th>\n",
              "      <th>S1_W_6</th>\n",
              "      <th>S1_W_7</th>\n",
              "      <th>S1_W_8</th>\n",
              "      <th>S1_W_9</th>\n",
              "      <th>S1_W_10</th>\n",
              "      <th>...</th>\n",
              "      <th>S4_W_11</th>\n",
              "      <th>S4_W_12</th>\n",
              "      <th>S4_W_13</th>\n",
              "      <th>S4_W_14</th>\n",
              "      <th>S4_W_15</th>\n",
              "      <th>S4_W_16</th>\n",
              "      <th>S4_W_17</th>\n",
              "      <th>S4_W_18</th>\n",
              "      <th>S4_YIELD</th>\n",
              "      <th>condition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21.430837</td>\n",
              "      <td>22.228488</td>\n",
              "      <td>24.205256</td>\n",
              "      <td>29.859199</td>\n",
              "      <td>30.434175</td>\n",
              "      <td>26.467017</td>\n",
              "      <td>27.300290</td>\n",
              "      <td>22.509277</td>\n",
              "      <td>16.388211</td>\n",
              "      <td>1.237347</td>\n",
              "      <td>...</td>\n",
              "      <td>0.879651</td>\n",
              "      <td>5.583977</td>\n",
              "      <td>0.319974</td>\n",
              "      <td>1.612761</td>\n",
              "      <td>3.304209</td>\n",
              "      <td>0.060819</td>\n",
              "      <td>1.540583</td>\n",
              "      <td>3.214933</td>\n",
              "      <td>5.77</td>\n",
              "      <td>Oui</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.841767</td>\n",
              "      <td>25.165941</td>\n",
              "      <td>24.169267</td>\n",
              "      <td>28.742330</td>\n",
              "      <td>27.342035</td>\n",
              "      <td>27.945379</td>\n",
              "      <td>25.710641</td>\n",
              "      <td>22.343698</td>\n",
              "      <td>19.797961</td>\n",
              "      <td>2.509957</td>\n",
              "      <td>...</td>\n",
              "      <td>2.556876</td>\n",
              "      <td>2.165009</td>\n",
              "      <td>2.165768</td>\n",
              "      <td>1.791010</td>\n",
              "      <td>3.012968</td>\n",
              "      <td>4.316012</td>\n",
              "      <td>2.021236</td>\n",
              "      <td>0.814444</td>\n",
              "      <td>8.65</td>\n",
              "      <td>Oui</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>23.067487</td>\n",
              "      <td>21.989987</td>\n",
              "      <td>26.730305</td>\n",
              "      <td>27.207224</td>\n",
              "      <td>28.277049</td>\n",
              "      <td>26.121537</td>\n",
              "      <td>30.583426</td>\n",
              "      <td>22.363784</td>\n",
              "      <td>15.826520</td>\n",
              "      <td>1.832929</td>\n",
              "      <td>...</td>\n",
              "      <td>2.468359</td>\n",
              "      <td>0.930159</td>\n",
              "      <td>1.402261</td>\n",
              "      <td>2.402111</td>\n",
              "      <td>2.140366</td>\n",
              "      <td>1.821273</td>\n",
              "      <td>1.763787</td>\n",
              "      <td>4.698325</td>\n",
              "      <td>6.34</td>\n",
              "      <td>Oui</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>24.441997</td>\n",
              "      <td>24.273763</td>\n",
              "      <td>23.400111</td>\n",
              "      <td>27.344886</td>\n",
              "      <td>25.011067</td>\n",
              "      <td>28.047828</td>\n",
              "      <td>25.841452</td>\n",
              "      <td>20.996116</td>\n",
              "      <td>16.747943</td>\n",
              "      <td>0.877913</td>\n",
              "      <td>...</td>\n",
              "      <td>1.782715</td>\n",
              "      <td>3.127549</td>\n",
              "      <td>0.520928</td>\n",
              "      <td>1.781335</td>\n",
              "      <td>2.064324</td>\n",
              "      <td>2.425123</td>\n",
              "      <td>3.876324</td>\n",
              "      <td>1.230727</td>\n",
              "      <td>3.93</td>\n",
              "      <td>Oui</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>21.562630</td>\n",
              "      <td>22.283709</td>\n",
              "      <td>25.263382</td>\n",
              "      <td>25.713687</td>\n",
              "      <td>28.258033</td>\n",
              "      <td>28.984649</td>\n",
              "      <td>26.601343</td>\n",
              "      <td>23.831066</td>\n",
              "      <td>17.453389</td>\n",
              "      <td>1.081927</td>\n",
              "      <td>...</td>\n",
              "      <td>5.300191</td>\n",
              "      <td>0.870621</td>\n",
              "      <td>0.466796</td>\n",
              "      <td>0.665607</td>\n",
              "      <td>2.231320</td>\n",
              "      <td>2.971977</td>\n",
              "      <td>1.737167</td>\n",
              "      <td>3.273389</td>\n",
              "      <td>5.58</td>\n",
              "      <td>Oui</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 77 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0e9295d-9b39-410d-8d01-6638731146cc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c0e9295d-9b39-410d-8d01-6638731146cc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c0e9295d-9b39-410d-8d01-6638731146cc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bb620046-d133-4329-8668-2b5b84f26238\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb620046-d133-4329-8668-2b5b84f26238')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bb620046-d133-4329-8668-2b5b84f26238 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Yield = np.array([data_interest.S1_YIELD,data_interest.S2_YIELD,data_interest.S3_YIELD,data_interest.S4_YIELD]).T"
      ],
      "metadata": {
        "id": "OBIA1hvWvX-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(data_interest.S1_YIELD, bins=200, alpha=0.5, color='red', label='1')\n",
        "plt.hist(data_interest.S2_YIELD, bins=200, alpha=0.5, color='green', label='2')\n",
        "plt.hist(data_interest.S3_YIELD, bins=200, alpha=0.5, color='blue', label='3')\n",
        "plt.hist(data_interest.S4_YIELD, bins=200, alpha=0.5, color='orange', label='4')\n",
        "\n",
        "plt.xlabel('Valeurs')\n",
        "plt.ylabel('Fréquence')\n",
        "plt.title('Distribution de 1, 2, 3, 4')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "BOLAJh2Kx-RM",
        "outputId": "d6edf67c-5613-45ac-d07e-00c95e9a144f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapté de la source ci apres :\n",
        "https://arxiv.org/abs/1907.00503"
      ],
      "metadata": {
        "id": "XhnjMjAje8Vq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Base Synth"
      ],
      "metadata": {
        "id": "ZmnOVjQtdd0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@contextlib.contextmanager\n",
        "def set_random_states(random_state, set_model_random_state):\n",
        "    \"\"\"Context manager for managing the random state.\n",
        "\n",
        "    Args:\n",
        "        random_state (int or tuple):\n",
        "            The random seed or a tuple of (numpy.random.RandomState, torch.Generator).\n",
        "        set_model_random_state (function):\n",
        "            Function to set the random state on the model.\n",
        "    \"\"\"\n",
        "    original_np_state = np.random.get_state()\n",
        "    original_torch_state = torch.get_rng_state()\n",
        "\n",
        "    random_np_state, random_torch_state = random_state\n",
        "\n",
        "    np.random.set_state(random_np_state.get_state())\n",
        "    torch.set_rng_state(random_torch_state.get_state())\n",
        "\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        current_np_state = np.random.RandomState()\n",
        "        current_np_state.set_state(np.random.get_state())\n",
        "        current_torch_state = torch.Generator()\n",
        "        current_torch_state.set_state(torch.get_rng_state())\n",
        "        set_model_random_state((current_np_state, current_torch_state))\n",
        "\n",
        "        np.random.set_state(original_np_state)\n",
        "        torch.set_rng_state(original_torch_state)\n",
        "\n",
        "\n",
        "def random_state(function):\n",
        "    \"\"\"Set the random state before calling the function.\n",
        "\n",
        "    Args:\n",
        "        function (Callable):\n",
        "            The function to wrap around.\n",
        "    \"\"\"\n",
        "\n",
        "    def wrapper(self, *args, **kwargs):\n",
        "        if self.random_states is None:\n",
        "            return function(self, *args, **kwargs)\n",
        "\n",
        "        else:\n",
        "            with set_random_states(self.random_states, self.set_random_state):\n",
        "                return function(self, *args, **kwargs)\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "class BaseSynthesizer:\n",
        "    \"\"\"Base class for all default synthesizers of ``CTGAN``.\"\"\"\n",
        "\n",
        "    random_states = None\n",
        "\n",
        "    def __getstate__(self):\n",
        "        \"\"\"Improve pickling state for ``BaseSynthesizer``.\n",
        "\n",
        "        Convert to ``cpu`` device before starting the pickling process in order to be able to\n",
        "        load the model even when used from an external tool such as ``SDV``. Also, if\n",
        "        ``random_states`` are set, store their states as dictionaries rather than generators.\n",
        "\n",
        "        Returns:\n",
        "            dict:\n",
        "                Python dict representing the object.\n",
        "        \"\"\"\n",
        "        device_backup = self._device\n",
        "        self.set_device(torch.device('cpu'))\n",
        "        state = self.__dict__.copy()\n",
        "        self.set_device(device_backup)\n",
        "        if (\n",
        "            isinstance(self.random_states, tuple) and\n",
        "            isinstance(self.random_states[0], np.random.RandomState) and\n",
        "            isinstance(self.random_states[1], torch.Generator)\n",
        "        ):\n",
        "            state['_numpy_random_state'] = self.random_states[0].get_state()\n",
        "            state['_torch_random_state'] = self.random_states[1].get_state()\n",
        "            state.pop('random_states')\n",
        "\n",
        "        return state\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        \"\"\"Restore the state of a ``BaseSynthesizer``.\n",
        "\n",
        "        Restore the ``random_states`` from the state dict if those are present and then\n",
        "        set the device according to the current hardware.\n",
        "        \"\"\"\n",
        "        if '_numpy_random_state' in state and '_torch_random_state' in state:\n",
        "            np_state = state.pop('_numpy_random_state')\n",
        "            torch_state = state.pop('_torch_random_state')\n",
        "\n",
        "            current_torch_state = torch.Generator()\n",
        "            current_torch_state.set_state(torch_state)\n",
        "\n",
        "            current_numpy_state = np.random.RandomState()\n",
        "            current_numpy_state.set_state(np_state)\n",
        "            state['random_states'] = (\n",
        "                current_numpy_state,\n",
        "                current_torch_state\n",
        "            )\n",
        "\n",
        "        self.__dict__ = state\n",
        "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        self.set_device(device)\n",
        "\n",
        "    def save(self, path):\n",
        "        \"\"\"Save the model in the passed `path`.\"\"\"\n",
        "        device_backup = self._device\n",
        "        self.set_device(torch.device('cpu'))\n",
        "        torch.save(self, path)\n",
        "        self.set_device(device_backup)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, path):\n",
        "        \"\"\"Load the model stored in the passed `path`.\"\"\"\n",
        "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        model = torch.load(path)\n",
        "        model.set_device(device)\n",
        "        return model\n",
        "\n",
        "    def set_random_state(self, random_state):\n",
        "        \"\"\"Set the random state.\n",
        "\n",
        "        Args:\n",
        "            random_state (int, tuple, or None):\n",
        "                Either a tuple containing the (numpy.random.RandomState, torch.Generator)\n",
        "                or an int representing the random seed to use for both random states.\n",
        "        \"\"\"\n",
        "        if random_state is None:\n",
        "            self.random_states = random_state\n",
        "        elif isinstance(random_state, int):\n",
        "            self.random_states = (\n",
        "                np.random.RandomState(seed=random_state),\n",
        "                torch.Generator().manual_seed(random_state),\n",
        "            )\n",
        "        elif (\n",
        "            isinstance(random_state, tuple) and\n",
        "            isinstance(random_state[0], np.random.RandomState) and\n",
        "            isinstance(random_state[1], torch.Generator)\n",
        "        ):\n",
        "            self.random_states = random_state\n",
        "        else:\n",
        "            raise TypeError(\n",
        "                f'`random_state` {random_state} expected to be an int or a tuple of '\n",
        "                '(`np.random.RandomState`, `torch.Generator`)')"
      ],
      "metadata": {
        "id": "r2gJ8lj9djj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataSampler"
      ],
      "metadata": {
        "id": "E4SPUVamfWqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataSampler(object):\n",
        "    \"\"\"DataSampler samples the conditional vector and corresponding data for CTGAN.\"\"\"\n",
        "\n",
        "    def __init__(self, data, output_info, log_frequency):\n",
        "        self._data_length = len(data)\n",
        "\n",
        "        def is_discrete_column(column_info):\n",
        "            return (len(column_info) == 1\n",
        "                    and column_info[0].activation_fn == 'softmax')\n",
        "\n",
        "        n_discrete_columns = sum(\n",
        "            [1 for column_info in output_info if is_discrete_column(column_info)])\n",
        "\n",
        "        self._discrete_column_matrix_st = np.zeros(\n",
        "            n_discrete_columns, dtype='int32')\n",
        "\n",
        "        # Store the row id for each category in each discrete column.\n",
        "        # For example _rid_by_cat_cols[a][b] is a list of all rows with the\n",
        "        # a-th discrete column equal value b.\n",
        "        self._rid_by_cat_cols = []\n",
        "\n",
        "        # Compute _rid_by_cat_cols\n",
        "        st = 0\n",
        "        for column_info in output_info:\n",
        "            if is_discrete_column(column_info):\n",
        "                span_info = column_info[0]\n",
        "                ed = st + span_info.dim\n",
        "\n",
        "                rid_by_cat = []\n",
        "                for j in range(span_info.dim):\n",
        "                    rid_by_cat.append(np.nonzero(data[:, st + j])[0])\n",
        "                self._rid_by_cat_cols.append(rid_by_cat)\n",
        "                st = ed\n",
        "            else:\n",
        "                st += sum([span_info.dim for span_info in column_info])\n",
        "        assert st == data.shape[1]\n",
        "\n",
        "        # Prepare an interval matrix for efficiently sample conditional vector\n",
        "        max_category = max([\n",
        "            column_info[0].dim\n",
        "            for column_info in output_info\n",
        "            if is_discrete_column(column_info)\n",
        "        ], default=0)\n",
        "\n",
        "        self._discrete_column_cond_st = np.zeros(n_discrete_columns, dtype='int32')\n",
        "        self._discrete_column_n_category = np.zeros(n_discrete_columns, dtype='int32')\n",
        "        self._discrete_column_category_prob = np.zeros((n_discrete_columns, max_category))\n",
        "        self._n_discrete_columns = n_discrete_columns\n",
        "        self._n_categories = sum([\n",
        "            column_info[0].dim\n",
        "            for column_info in output_info\n",
        "            if is_discrete_column(column_info)\n",
        "        ])\n",
        "\n",
        "        st = 0\n",
        "        current_id = 0\n",
        "        current_cond_st = 0\n",
        "        for column_info in output_info:\n",
        "            if is_discrete_column(column_info):\n",
        "                span_info = column_info[0]\n",
        "                ed = st + span_info.dim\n",
        "                category_freq = np.sum(data[:, st:ed], axis=0)\n",
        "                if log_frequency:\n",
        "                    category_freq = np.log(category_freq + 1)\n",
        "                category_prob = category_freq / np.sum(category_freq)\n",
        "                self._discrete_column_category_prob[current_id, :span_info.dim] = category_prob\n",
        "                self._discrete_column_cond_st[current_id] = current_cond_st\n",
        "                self._discrete_column_n_category[current_id] = span_info.dim\n",
        "                current_cond_st += span_info.dim\n",
        "                current_id += 1\n",
        "                st = ed\n",
        "            else:\n",
        "                st += sum([span_info.dim for span_info in column_info])\n",
        "\n",
        "    def _random_choice_prob_index(self, discrete_column_id):\n",
        "        probs = self._discrete_column_category_prob[discrete_column_id]\n",
        "        r = np.expand_dims(np.random.rand(probs.shape[0]), axis=1)\n",
        "        return (probs.cumsum(axis=1) > r).argmax(axis=1)\n",
        "\n",
        "    def sample_condvec(self, batch):\n",
        "        \"\"\"Generate the conditional vector for training.\n",
        "\n",
        "        Returns:\n",
        "            cond (batch x #categories):\n",
        "                The conditional vector.\n",
        "            mask (batch x #discrete columns):\n",
        "                A one-hot vector indicating the selected discrete column.\n",
        "            discrete column id (batch):\n",
        "                Integer representation of mask.\n",
        "            category_id_in_col (batch):\n",
        "                Selected category in the selected discrete column.\n",
        "        \"\"\"\n",
        "        if self._n_discrete_columns == 0:\n",
        "            return None\n",
        "\n",
        "        discrete_column_id = np.random.choice(\n",
        "            np.arange(self._n_discrete_columns), batch)\n",
        "\n",
        "        cond = np.zeros((batch, self._n_categories), dtype='float32')\n",
        "        mask = np.zeros((batch, self._n_discrete_columns), dtype='float32')\n",
        "        mask[np.arange(batch), discrete_column_id] = 1\n",
        "        category_id_in_col = self._random_choice_prob_index(discrete_column_id)\n",
        "        category_id = (self._discrete_column_cond_st[discrete_column_id] + category_id_in_col)\n",
        "        cond[np.arange(batch), category_id] = 1\n",
        "\n",
        "        return cond, mask, discrete_column_id, category_id_in_col\n",
        "\n",
        "    def sample_original_condvec(self, batch):\n",
        "        \"\"\"Generate the conditional vector for generation use original frequency.\"\"\"\n",
        "        if self._n_discrete_columns == 0:\n",
        "            return None\n",
        "\n",
        "        category_freq = self._discrete_column_category_prob.flatten()\n",
        "        category_freq = category_freq[category_freq != 0]\n",
        "        category_freq = category_freq / np.sum(category_freq)\n",
        "        col_idxs = np.random.choice(np.arange(len(category_freq)), batch, p=category_freq)\n",
        "        cond = np.zeros((batch, self._n_categories), dtype='float32')\n",
        "        cond[np.arange(batch), col_idxs] = 1\n",
        "\n",
        "        return cond\n",
        "\n",
        "    def sample_data(self, data, n, col, opt):\n",
        "        \"\"\"Sample data from original training data satisfying the sampled conditional vector.\n",
        "\n",
        "        Args:\n",
        "            data:\n",
        "                The training data.\n",
        "        Returns:\n",
        "            n:\n",
        "                n rows of matrix data.\n",
        "        \"\"\"\n",
        "        if col is None:\n",
        "            idx = np.random.randint(len(data), size=n)\n",
        "            return data[idx]\n",
        "\n",
        "        idx = []\n",
        "        for c, o in zip(col, opt):\n",
        "            idx.append(np.random.choice(self._rid_by_cat_cols[c][o]))\n",
        "\n",
        "        return data[idx]\n",
        "\n",
        "    def dim_cond_vec(self):\n",
        "        \"\"\"Return the total number of categories.\"\"\"\n",
        "        return self._n_categories\n",
        "\n",
        "    def generate_cond_from_condition_column_info(self, condition_info, batch):\n",
        "        \"\"\"Generate the condition vector.\"\"\"\n",
        "        vec = np.zeros((batch, self._n_categories), dtype='float32')\n",
        "        id_ = self._discrete_column_matrix_st[condition_info['discrete_column_id']]\n",
        "        id_ += condition_info['value_id']\n",
        "        vec[:, id_] = 1\n",
        "        return vec"
      ],
      "metadata": {
        "id": "4l0phSByfYLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataTransformer"
      ],
      "metadata": {
        "id": "Wj1SY91Tfhcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SpanInfo = namedtuple('SpanInfo', ['dim', 'activation_fn'])\n",
        "ColumnTransformInfo = namedtuple(\n",
        "    'ColumnTransformInfo', [\n",
        "        'column_name', 'column_type', 'transform', 'output_info', 'output_dimensions'\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "class DataTransformer(object):\n",
        "    \"\"\"Data Transformer.\n",
        "\n",
        "    Model continuous columns with a BayesianGMM and normalize them to a scalar between [-1, 1]\n",
        "    and a vector. Discrete columns are encoded using a OneHotEncoder.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_clusters=10, weight_threshold=0.005):\n",
        "        \"\"\"Create a data transformer.\n",
        "\n",
        "        Args:\n",
        "            max_clusters (int):\n",
        "                Maximum number of Gaussian distributions in Bayesian GMM.\n",
        "            weight_threshold (float):\n",
        "                Weight threshold for a Gaussian distribution to be kept.\n",
        "        \"\"\"\n",
        "        self._max_clusters = max_clusters\n",
        "        self._weight_threshold = weight_threshold\n",
        "\n",
        "    def _fit_continuous(self, data):\n",
        "        \"\"\"Train Bayesian GMM for continuous columns.\n",
        "\n",
        "        Args:\n",
        "            data (pd.DataFrame):\n",
        "                A dataframe containing a column.\n",
        "\n",
        "        Returns:\n",
        "            namedtuple:\n",
        "                A ``ColumnTransformInfo`` object.\n",
        "        \"\"\"\n",
        "        column_name = data.columns[0]\n",
        "        gm = ClusterBasedNormalizer(\n",
        "            missing_value_generation='from_column',\n",
        "            max_clusters=min(len(data), self._max_clusters),\n",
        "            weight_threshold=self._weight_threshold\n",
        "        )\n",
        "        gm.fit(data, column_name)\n",
        "        num_components = sum(gm.valid_component_indicator)\n",
        "\n",
        "        return ColumnTransformInfo(\n",
        "            column_name=column_name, column_type='continuous', transform=gm,\n",
        "            output_info=[SpanInfo(1, 'tanh'), SpanInfo(num_components, 'softmax')],\n",
        "            output_dimensions=1 + num_components)\n",
        "\n",
        "    def _fit_discrete(self, data):\n",
        "        \"\"\"Fit one hot encoder for discrete column.\n",
        "\n",
        "        Args:\n",
        "            data (pd.DataFrame):\n",
        "                A dataframe containing a column.\n",
        "\n",
        "        Returns:\n",
        "            namedtuple:\n",
        "                A ``ColumnTransformInfo`` object.\n",
        "        \"\"\"\n",
        "        column_name = data.columns[0]\n",
        "        ohe = OneHotEncoder()\n",
        "        ohe.fit(data, column_name)\n",
        "        num_categories = len(ohe.dummies)\n",
        "\n",
        "        return ColumnTransformInfo(\n",
        "            column_name=column_name, column_type='discrete', transform=ohe,\n",
        "            output_info=[SpanInfo(num_categories, 'softmax')],\n",
        "            output_dimensions=num_categories)\n",
        "\n",
        "    def fit(self, raw_data, discrete_columns=()):\n",
        "        \"\"\"Fit the ``DataTransformer``.\n",
        "\n",
        "        Fits a ``ClusterBasedNormalizer`` for continuous columns and a\n",
        "        ``OneHotEncoder`` for discrete columns.\n",
        "\n",
        "        This step also counts the #columns in matrix data and span information.\n",
        "        \"\"\"\n",
        "        self.output_info_list = []\n",
        "        self.output_dimensions = 0\n",
        "        self.dataframe = True\n",
        "\n",
        "        if not isinstance(raw_data, pd.DataFrame):\n",
        "            self.dataframe = False\n",
        "            # work around for RDT issue #328 Fitting with numerical column names fails\n",
        "            discrete_columns = [str(column) for column in discrete_columns]\n",
        "            column_names = [str(num) for num in range(raw_data.shape[1])]\n",
        "            raw_data = pd.DataFrame(raw_data, columns=column_names)\n",
        "\n",
        "        self._column_raw_dtypes = raw_data.infer_objects().dtypes\n",
        "        self._column_transform_info_list = []\n",
        "        for column_name in raw_data.columns:\n",
        "            if column_name in discrete_columns:\n",
        "                column_transform_info = self._fit_discrete(raw_data[[column_name]])\n",
        "            else:\n",
        "                column_transform_info = self._fit_continuous(raw_data[[column_name]])\n",
        "\n",
        "            self.output_info_list.append(column_transform_info.output_info)\n",
        "            self.output_dimensions += column_transform_info.output_dimensions\n",
        "            self._column_transform_info_list.append(column_transform_info)\n",
        "\n",
        "    def _transform_continuous(self, column_transform_info, data):\n",
        "        column_name = data.columns[0]\n",
        "        flattened_column = data[column_name].to_numpy().flatten()\n",
        "        data = data.assign(**{column_name: flattened_column})\n",
        "        gm = column_transform_info.transform\n",
        "        transformed = gm.transform(data)\n",
        "\n",
        "        #  Converts the transformed data to the appropriate output format.\n",
        "        #  The first column (ending in '.normalized') stays the same,\n",
        "        #  but the lable encoded column (ending in '.component') is one hot encoded.\n",
        "        output = np.zeros((len(transformed), column_transform_info.output_dimensions))\n",
        "        output[:, 0] = transformed[f'{column_name}.normalized'].to_numpy()\n",
        "        index = transformed[f'{column_name}.component'].to_numpy().astype(int)\n",
        "        output[np.arange(index.size), index + 1] = 1.0\n",
        "\n",
        "        return output\n",
        "\n",
        "    def _transform_discrete(self, column_transform_info, data):\n",
        "        ohe = column_transform_info.transform\n",
        "        return ohe.transform(data).to_numpy()\n",
        "\n",
        "    def _synchronous_transform(self, raw_data, column_transform_info_list):\n",
        "        \"\"\"Take a Pandas DataFrame and transform columns synchronous.\n",
        "\n",
        "        Outputs a list with Numpy arrays.\n",
        "        \"\"\"\n",
        "        column_data_list = []\n",
        "        for column_transform_info in column_transform_info_list:\n",
        "            column_name = column_transform_info.column_name\n",
        "            data = raw_data[[column_name]]\n",
        "            if column_transform_info.column_type == 'continuous':\n",
        "                column_data_list.append(self._transform_continuous(column_transform_info, data))\n",
        "            else:\n",
        "                column_data_list.append(self._transform_discrete(column_transform_info, data))\n",
        "\n",
        "        return column_data_list\n",
        "\n",
        "    def _parallel_transform(self, raw_data, column_transform_info_list):\n",
        "        \"\"\"Take a Pandas DataFrame and transform columns in parallel.\n",
        "\n",
        "        Outputs a list with Numpy arrays.\n",
        "        \"\"\"\n",
        "        processes = []\n",
        "        for column_transform_info in column_transform_info_list:\n",
        "            column_name = column_transform_info.column_name\n",
        "            data = raw_data[[column_name]]\n",
        "            process = None\n",
        "            if column_transform_info.column_type == 'continuous':\n",
        "                process = delayed(self._transform_continuous)(column_transform_info, data)\n",
        "            else:\n",
        "                process = delayed(self._transform_discrete)(column_transform_info, data)\n",
        "            processes.append(process)\n",
        "\n",
        "        return Parallel(n_jobs=-1)(processes)\n",
        "\n",
        "    def transform(self, raw_data):\n",
        "        \"\"\"Take raw data and output a matrix data.\"\"\"\n",
        "        if not isinstance(raw_data, pd.DataFrame):\n",
        "            column_names = [str(num) for num in range(raw_data.shape[1])]\n",
        "            raw_data = pd.DataFrame(raw_data, columns=column_names)\n",
        "\n",
        "        # Only use parallelization with larger data sizes.\n",
        "        # Otherwise, the transformation will be slower.\n",
        "        if raw_data.shape[0] < 500:\n",
        "            column_data_list = self._synchronous_transform(\n",
        "                raw_data,\n",
        "                self._column_transform_info_list\n",
        "            )\n",
        "        else:\n",
        "            column_data_list = self._parallel_transform(\n",
        "                raw_data,\n",
        "                self._column_transform_info_list\n",
        "            )\n",
        "\n",
        "        return np.concatenate(column_data_list, axis=1).astype(float)\n",
        "\n",
        "    def _inverse_transform_continuous(self, column_transform_info, column_data, sigmas, st):\n",
        "        gm = column_transform_info.transform\n",
        "        data = pd.DataFrame(column_data[:, :2], columns=list(gm.get_output_sdtypes()))\n",
        "        data[data.columns[1]] = np.argmax(column_data[:, 1:], axis=1)\n",
        "        if sigmas is not None:\n",
        "            selected_normalized_value = np.random.normal(data.iloc[:, 0], sigmas[st])\n",
        "            data.iloc[:, 0] = selected_normalized_value\n",
        "\n",
        "        return gm.reverse_transform(data)\n",
        "\n",
        "    def _inverse_transform_discrete(self, column_transform_info, column_data):\n",
        "        ohe = column_transform_info.transform\n",
        "        data = pd.DataFrame(column_data, columns=list(ohe.get_output_sdtypes()))\n",
        "        return ohe.reverse_transform(data)[column_transform_info.column_name]\n",
        "\n",
        "    def inverse_transform(self, data, sigmas=None):\n",
        "        \"\"\"Take matrix data and output raw data.\n",
        "\n",
        "        Output uses the same type as input to the transform function.\n",
        "        Either np array or pd dataframe.\n",
        "        \"\"\"\n",
        "        st = 0\n",
        "        recovered_column_data_list = []\n",
        "        column_names = []\n",
        "        for column_transform_info in self._column_transform_info_list:\n",
        "            dim = column_transform_info.output_dimensions\n",
        "            column_data = data[:, st:st + dim]\n",
        "            if column_transform_info.column_type == 'continuous':\n",
        "                recovered_column_data = self._inverse_transform_continuous(\n",
        "                    column_transform_info, column_data, sigmas, st)\n",
        "            else:\n",
        "                recovered_column_data = self._inverse_transform_discrete(\n",
        "                    column_transform_info, column_data)\n",
        "\n",
        "            recovered_column_data_list.append(recovered_column_data)\n",
        "            column_names.append(column_transform_info.column_name)\n",
        "            st += dim\n",
        "\n",
        "        recovered_data = np.column_stack(recovered_column_data_list)\n",
        "        recovered_data = (pd.DataFrame(recovered_data, columns=column_names)\n",
        "                          .astype(self._column_raw_dtypes))\n",
        "        if not self.dataframe:\n",
        "            recovered_data = recovered_data.to_numpy()\n",
        "\n",
        "        return recovered_data\n",
        "\n",
        "    def convert_column_name_value_to_id(self, column_name, value):\n",
        "        \"\"\"Get the ids of the given `column_name`.\"\"\"\n",
        "        discrete_counter = 0\n",
        "        column_id = 0\n",
        "        for column_transform_info in self._column_transform_info_list:\n",
        "            if column_transform_info.column_name == column_name:\n",
        "                break\n",
        "            if column_transform_info.column_type == 'discrete':\n",
        "                discrete_counter += 1\n",
        "\n",
        "            column_id += 1\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"The column_name `{column_name}` doesn't exist in the data.\")\n",
        "\n",
        "        ohe = column_transform_info.transform\n",
        "        data = pd.DataFrame([value], columns=[column_transform_info.column_name])\n",
        "        one_hot = ohe.transform(data).to_numpy()[0]\n",
        "        if sum(one_hot) == 0:\n",
        "            raise ValueError(f\"The value `{value}` doesn't exist in the column `{column_name}`.\")\n",
        "\n",
        "        return {\n",
        "            'discrete_column_id': discrete_counter,\n",
        "            'column_id': column_id,\n",
        "            'value_id': np.argmax(one_hot)\n",
        "        }"
      ],
      "metadata": {
        "id": "nxJiHLEofigq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelisation T-GANs"
      ],
      "metadata": {
        "id": "MfXr02mmmMnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\"Discriminator for the CTGAN.\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, discriminator_dim, pac=10, transformer_nhead=1, transformer_dim_feedforward=2048):\n",
        "        super(Discriminator, self).__init__()\n",
        "        dim = input_dim * pac\n",
        "        self.pac = pac\n",
        "        self.pacdim = dim\n",
        "\n",
        "        # Ajouter des couches transformer\n",
        "        self.transformer_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=transformer_nhead, dim_feedforward=transformer_dim_feedforward)\n",
        "        self.transformer = nn.TransformerEncoder(self.transformer_layer, num_layers=1)\n",
        "\n",
        "        # Ajouter des couches linéaires et d'autres couches discriminatoires\n",
        "        seq = []\n",
        "        for item in list(discriminator_dim):\n",
        "            seq += [Linear(dim, item), LeakyReLU(0.2), Dropout(0.5)]\n",
        "            dim = item\n",
        "\n",
        "        seq += [Linear(dim, 1)]\n",
        "        self.seq = nn.Sequential(*seq)\n",
        "\n",
        "    def calc_gradient_penalty(self, real_data, fake_data, device='cpu', pac=10, lambda_=10):\n",
        "        \"\"\"Compute the gradient penalty.\"\"\"\n",
        "        alpha = torch.rand(real_data.size(0) // pac, 1, 1, device=device)\n",
        "        alpha = alpha.repeat(1, pac, real_data.size(1))\n",
        "        alpha = alpha.view(-1, real_data.size(1))\n",
        "\n",
        "        interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
        "\n",
        "        disc_interpolates = self(interpolates)\n",
        "\n",
        "        gradients = torch.autograd.grad(\n",
        "            outputs=disc_interpolates, inputs=interpolates,\n",
        "            grad_outputs=torch.ones(disc_interpolates.size(), device=device),\n",
        "            create_graph=True, retain_graph=True, only_inputs=True\n",
        "        )[0]\n",
        "\n",
        "        gradients_view = gradients.view(-1, pac * real_data.size(1)).norm(2, dim=1) - 1\n",
        "        gradient_penalty = ((gradients_view) ** 2).mean() * lambda_\n",
        "\n",
        "        return gradient_penalty\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Appliquer la transformation avec le transformer\n",
        "        x_transformed = self.transformer(x)\n",
        "\n",
        "        # Appliquer les autres couches discriminatoires\n",
        "        return self.seq(x_transformed)\n",
        "\n",
        "\n",
        "class Residual(Module):\n",
        "    \"\"\"Residual layer for the CTGAN.\"\"\"\n",
        "\n",
        "    def __init__(self, i, o):\n",
        "        super(Residual, self).__init__()\n",
        "        self.fc = Linear(i, o)\n",
        "        self.bn = BatchNorm1d(o)\n",
        "        self.relu = ReLU()\n",
        "\n",
        "    def forward(self, input_):\n",
        "        \"\"\"Apply the Residual layer to the `input_`.\"\"\"\n",
        "        out = self.fc(input_)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        return torch.cat([out, input_], dim=1)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"Generator for the CTGAN.\"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim, generator_dim, data_dim, transformer_nhead=1, transformer_dim_feedforward=2048):\n",
        "        super(Generator, self).__init__()\n",
        "        dim = embedding_dim\n",
        "\n",
        "        # Ajouter des couches transformer\n",
        "        self.transformer_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=transformer_nhead, dim_feedforward=transformer_dim_feedforward)\n",
        "        self.transformer = nn.TransformerEncoder(self.transformer_layer, num_layers=1)\n",
        "\n",
        "        # Ajouter des couches résiduelles\n",
        "        seq = []\n",
        "        for item in list(generator_dim):\n",
        "            seq += [Residual(dim, item)]\n",
        "            dim += item\n",
        "\n",
        "        seq.append(Linear(dim, data_dim))\n",
        "        self.seq = nn.Sequential(*seq)\n",
        "\n",
        "    def forward(self, input_):\n",
        "        \"\"\"Apply the Generator to the `input_`.\"\"\"\n",
        "        # Appliquer la transformation avec le transformer\n",
        "        input_transformed = self.transformer(input_)\n",
        "\n",
        "        # Appliquer les autres couches résiduelles\n",
        "        data = self.seq(input_transformed)\n",
        "        return data\n",
        "\n",
        "\n",
        "class CTGAN(BaseSynthesizer):\n",
        "    \"\"\"Conditional Table GAN Synthesizer.\n",
        "\n",
        "    This is the core class of the CTGAN project, where the different components\n",
        "    are orchestrated together.\n",
        "    For more details about the process, please check the [Modeling Tabular data using\n",
        "    Conditional GAN](https://arxiv.org/abs/1907.00503) paper.\n",
        "\n",
        "    Args:\n",
        "        embedding_dim (int):\n",
        "            Size of the random sample passed to the Generator. Defaults to 128.\n",
        "        generator_dim (tuple or list of ints):\n",
        "            Size of the output samples for each one of the Residuals. A Residual Layer\n",
        "            will be created for each one of the values provided. Defaults to (256, 256).\n",
        "        discriminator_dim (tuple or list of ints):\n",
        "            Size of the output samples for each one of the Discriminator Layers. A Linear Layer\n",
        "            will be created for each one of the values provided. Defaults to (256, 256).\n",
        "        generator_lr (float):\n",
        "            Learning rate for the generator. Defaults to 2e-4.\n",
        "        generator_decay (float):\n",
        "            Generator weight decay for the Adam Optimizer. Defaults to 1e-6.\n",
        "        discriminator_lr (float):\n",
        "            Learning rate for the discriminator. Defaults to 2e-4.\n",
        "        discriminator_decay (float):\n",
        "            Discriminator weight decay for the Adam Optimizer. Defaults to 1e-6.\n",
        "        batch_size (int):\n",
        "            Number of data samples to process in each step.\n",
        "        discriminator_steps (int):\n",
        "            Number of discriminator updates to do for each generator update.\n",
        "            From the WGAN paper: https://arxiv.org/abs/1701.07875. WGAN paper\n",
        "            default is 5. Default used is 1 to match original CTGAN implementation.\n",
        "        log_frequency (boolean):\n",
        "            Whether to use log frequency of categorical levels in conditional\n",
        "            sampling. Defaults to ``True``.\n",
        "        verbose (boolean):\n",
        "            Whether to have print statements for progress results. Defaults to ``False``.\n",
        "        epochs (int):\n",
        "            Number of training epochs. Defaults to 300.\n",
        "        pac (int):\n",
        "            Number of samples to group together when applying the discriminator.\n",
        "            Defaults to 10.\n",
        "        cuda (bool):\n",
        "            Whether to attempt to use cuda for GPU computation.\n",
        "            If this is False or CUDA is not available, CPU will be used.\n",
        "            Defaults to ``True``.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim=50, generator_dim=(256, 256), discriminator_dim=(256, 256),\n",
        "                 generator_lr=2e-4, generator_decay=1e-6, discriminator_lr=2e-4,\n",
        "                 discriminator_decay=1e-6, batch_size=500, discriminator_steps=1,\n",
        "                 log_frequency=True, verbose=False, epochs=300, pac=10, cuda=True):\n",
        "\n",
        "        assert batch_size % 2 == 0\n",
        "\n",
        "        self._embedding_dim = embedding_dim\n",
        "        self._generator_dim = generator_dim\n",
        "        self._discriminator_dim = discriminator_dim\n",
        "\n",
        "        self._generator_lr = generator_lr\n",
        "        self._generator_decay = generator_decay\n",
        "        self._discriminator_lr = discriminator_lr\n",
        "        self._discriminator_decay = discriminator_decay\n",
        "\n",
        "        self._batch_size = batch_size\n",
        "        self._discriminator_steps = discriminator_steps\n",
        "        self._log_frequency = log_frequency\n",
        "        self._verbose = verbose\n",
        "        self._epochs = epochs\n",
        "        self.pac = pac\n",
        "\n",
        "        if not cuda or not torch.cuda.is_available():\n",
        "            device = 'cpu'\n",
        "        elif isinstance(cuda, str):\n",
        "            device = cuda\n",
        "        else:\n",
        "            device = 'cuda'\n",
        "\n",
        "        self._device = torch.device(device)\n",
        "\n",
        "        self._transformer = None\n",
        "        self._data_sampler = None\n",
        "        self._generator = None\n",
        "\n",
        "        self.loss_values = pd.DataFrame(columns=['Epoch', 'Generator Loss', 'Distriminator Loss'])\n",
        "\n",
        "    @staticmethod\n",
        "    def _gumbel_softmax(logits, tau=1, hard=False, eps=1e-10, dim=-1):\n",
        "        \"\"\"Deals with the instability of the gumbel_softmax for older versions of torch.\n",
        "\n",
        "        For more details about the issue:\n",
        "        https://drive.google.com/file/d/1AA5wPfZ1kquaRtVruCd6BiYZGcDeNxyP/view?usp=sharing\n",
        "\n",
        "        Args:\n",
        "            logits […, num_features]:\n",
        "                Unnormalized log probabilities\n",
        "            tau:\n",
        "                Non-negative scalar temperature\n",
        "            hard (bool):\n",
        "                If True, the returned samples will be discretized as one-hot vectors,\n",
        "                but will be differentiated as if it is the soft sample in autograd\n",
        "            dim (int):\n",
        "                A dimension along which softmax will be computed. Default: -1.\n",
        "\n",
        "        Returns:\n",
        "            Sampled tensor of same shape as logits from the Gumbel-Softmax distribution.\n",
        "        \"\"\"\n",
        "        for _ in range(10):\n",
        "            transformed = functional.gumbel_softmax(logits, tau=tau, hard=hard, eps=eps, dim=dim)\n",
        "            if not torch.isnan(transformed).any():\n",
        "                return transformed\n",
        "\n",
        "        raise ValueError('gumbel_softmax returning NaN.')\n",
        "\n",
        "    def _apply_activate(self, data):\n",
        "        \"\"\"Apply proper activation function to the output of the generator.\"\"\"\n",
        "        data_t = []\n",
        "        st = 0\n",
        "        for column_info in self._transformer.output_info_list:\n",
        "            for span_info in column_info:\n",
        "                if span_info.activation_fn == 'tanh':\n",
        "                    ed = st + span_info.dim\n",
        "                    data_t.append(torch.tanh(data[:, st:ed]))\n",
        "                    st = ed\n",
        "                elif span_info.activation_fn == 'softmax':\n",
        "                    ed = st + span_info.dim\n",
        "                    transformed = self._gumbel_softmax(data[:, st:ed], tau=0.2)\n",
        "                    data_t.append(transformed)\n",
        "                    st = ed\n",
        "                else:\n",
        "                    raise ValueError(f'Unexpected activation function {span_info.activation_fn}.')\n",
        "\n",
        "        return torch.cat(data_t, dim=1)\n",
        "\n",
        "    def _cond_loss(self, data, c, m):\n",
        "        \"\"\"Compute the cross entropy loss on the fixed discrete column.\"\"\"\n",
        "        loss = []\n",
        "        st = 0\n",
        "        st_c = 0\n",
        "        for column_info in self._transformer.output_info_list:\n",
        "            for span_info in column_info:\n",
        "                if len(column_info) != 1 or span_info.activation_fn != 'softmax':\n",
        "                    # not discrete column\n",
        "                    st += span_info.dim\n",
        "                else:\n",
        "                    ed = st + span_info.dim\n",
        "                    ed_c = st_c + span_info.dim\n",
        "                    tmp = functional.cross_entropy(\n",
        "                        data[:, st:ed],\n",
        "                        torch.argmax(c[:, st_c:ed_c], dim=1),\n",
        "                        reduction='none'\n",
        "                    )\n",
        "                    loss.append(tmp)\n",
        "                    st = ed\n",
        "                    st_c = ed_c\n",
        "\n",
        "        loss = torch.stack(loss, dim=1)  # noqa: PD013\n",
        "\n",
        "        return (loss * m).sum() / data.size()[0]\n",
        "\n",
        "    def _validate_discrete_columns(self, train_data, discrete_columns):\n",
        "        \"\"\"Check whether ``discrete_columns`` exists in ``train_data``.\n",
        "\n",
        "        Args:\n",
        "            train_data (numpy.ndarray or pandas.DataFrame):\n",
        "                Training Data. It must be a 2-dimensional numpy array or a pandas.DataFrame.\n",
        "            discrete_columns (list-like):\n",
        "                List of discrete columns to be used to generate the Conditional\n",
        "                Vector. If ``train_data`` is a Numpy array, this list should\n",
        "                contain the integer indices of the columns. Otherwise, if it is\n",
        "                a ``pandas.DataFrame``, this list should contain the column names.\n",
        "        \"\"\"\n",
        "        if isinstance(train_data, pd.DataFrame):\n",
        "            invalid_columns = set(discrete_columns) - set(train_data.columns)\n",
        "        elif isinstance(train_data, np.ndarray):\n",
        "            invalid_columns = []\n",
        "            for column in discrete_columns:\n",
        "                if column < 0 or column >= train_data.shape[1]:\n",
        "                    invalid_columns.append(column)\n",
        "        else:\n",
        "            raise TypeError('``train_data`` should be either pd.DataFrame or np.array.')\n",
        "\n",
        "        if invalid_columns:\n",
        "            raise ValueError(f'Invalid columns found: {invalid_columns}')\n",
        "\n",
        "    @random_state\n",
        "    def fit(self, train_data, discrete_columns=(), epochs=None):\n",
        "        \"\"\"Fit the CTGAN Synthesizer models to the training data.\n",
        "\n",
        "        Args:\n",
        "            train_data (numpy.ndarray or pandas.DataFrame):\n",
        "                Training Data. It must be a 2-dimensional numpy array or a pandas.DataFrame.\n",
        "            discrete_columns (list-like):\n",
        "                List of discrete columns to be used to generate the Conditional\n",
        "                Vector. If ``train_data`` is a Numpy array, this list should\n",
        "                contain the integer indices of the columns. Otherwise, if it is\n",
        "                a ``pandas.DataFrame``, this list should contain the column names.\n",
        "        \"\"\"\n",
        "        self._validate_discrete_columns(train_data, discrete_columns)\n",
        "\n",
        "        if epochs is None:\n",
        "            epochs = self._epochs\n",
        "        else:\n",
        "            warnings.warn(\n",
        "                ('`epochs` argument in `fit` method has been deprecated and will be removed '\n",
        "                 'in a future version. Please pass `epochs` to the constructor instead'),\n",
        "                DeprecationWarning\n",
        "            )\n",
        "\n",
        "        self._transformer = DataTransformer()\n",
        "        self._transformer.fit(train_data, discrete_columns)\n",
        "\n",
        "        train_data = self._transformer.transform(train_data)\n",
        "\n",
        "        self._data_sampler = DataSampler(\n",
        "            train_data,\n",
        "            self._transformer.output_info_list,\n",
        "            self._log_frequency)\n",
        "\n",
        "        data_dim = self._transformer.output_dimensions\n",
        "\n",
        "        self._generator = Generator(\n",
        "            self._embedding_dim + self._data_sampler.dim_cond_vec(),\n",
        "            self._generator_dim,\n",
        "            data_dim\n",
        "        ).to(self._device)\n",
        "\n",
        "        discriminator = Discriminator(\n",
        "            data_dim + self._data_sampler.dim_cond_vec(),\n",
        "            self._discriminator_dim,\n",
        "            pac=self.pac\n",
        "        ).to(self._device)\n",
        "\n",
        "        optimizerG = optim.Adam(\n",
        "            self._generator.parameters(), lr=self._generator_lr, betas=(0.5, 0.9),\n",
        "            weight_decay=self._generator_decay\n",
        "        )\n",
        "\n",
        "        optimizerD = optim.Adam(\n",
        "            discriminator.parameters(), lr=self._discriminator_lr,\n",
        "            betas=(0.5, 0.9), weight_decay=self._discriminator_decay\n",
        "        )\n",
        "\n",
        "        mean = torch.zeros(self._batch_size, self._embedding_dim, device=self._device)\n",
        "        std = mean + 1\n",
        "\n",
        "        self.loss_values = pd.DataFrame(columns=['Epoch', 'Generator Loss', 'Distriminator Loss'])\n",
        "\n",
        "        epoch_iterator = tqdm(range(epochs), disable=(not self._verbose))\n",
        "        if self._verbose:\n",
        "            description = 'Gen. ({gen:.2f}) | Discrim. ({dis:.2f})'\n",
        "            epoch_iterator.set_description(description.format(gen=0, dis=0))\n",
        "\n",
        "        steps_per_epoch = max(len(train_data) // self._batch_size, 1)\n",
        "        for i in epoch_iterator:\n",
        "            for id_ in range(steps_per_epoch):\n",
        "\n",
        "                for n in range(self._discriminator_steps):\n",
        "                    fakez = torch.normal(mean=mean, std=std)\n",
        "\n",
        "                    condvec = self._data_sampler.sample_condvec(self._batch_size)\n",
        "                    if condvec is None:\n",
        "                        c1, m1, col, opt = None, None, None, None\n",
        "                        real = self._data_sampler.sample_data(\n",
        "                            train_data, self._batch_size, col, opt)\n",
        "                    else:\n",
        "                        c1, m1, col, opt = condvec\n",
        "                        c1 = torch.from_numpy(c1).to(self._device)\n",
        "                        m1 = torch.from_numpy(m1).to(self._device)\n",
        "                        fakez = torch.cat([fakez, c1], dim=1)\n",
        "\n",
        "                        perm = np.arange(self._batch_size)\n",
        "                        np.random.shuffle(perm)\n",
        "                        real = self._data_sampler.sample_data(\n",
        "                            train_data, self._batch_size, col[perm], opt[perm])\n",
        "                        c2 = c1[perm]\n",
        "\n",
        "                    fake = self._generator(fakez)\n",
        "                    fakeact = self._apply_activate(fake)\n",
        "\n",
        "                    real = torch.from_numpy(real.astype('float32')).to(self._device)\n",
        "\n",
        "                    if c1 is not None:\n",
        "                        fake_cat = torch.cat([fakeact, c1], dim=1)\n",
        "                        real_cat = torch.cat([real, c2], dim=1)\n",
        "                    else:\n",
        "                        real_cat = real\n",
        "                        fake_cat = fakeact\n",
        "\n",
        "                    y_fake = discriminator(fake_cat)\n",
        "                    y_real = discriminator(real_cat)\n",
        "\n",
        "                    pen = discriminator.calc_gradient_penalty(\n",
        "                        real_cat, fake_cat, self._device, self.pac)\n",
        "                    loss_d = -(torch.mean(y_real) - torch.mean(y_fake))\n",
        "\n",
        "                    optimizerD.zero_grad(set_to_none=False)\n",
        "                    pen.backward(retain_graph=True)\n",
        "                    loss_d.backward()\n",
        "                    optimizerD.step()\n",
        "\n",
        "                fakez = torch.normal(mean=mean, std=std)\n",
        "                condvec = self._data_sampler.sample_condvec(self._batch_size)\n",
        "\n",
        "                if condvec is None:\n",
        "                    c1, m1, col, opt = None, None, None, None\n",
        "                else:\n",
        "                    c1, m1, col, opt = condvec\n",
        "                    c1 = torch.from_numpy(c1).to(self._device)\n",
        "                    m1 = torch.from_numpy(m1).to(self._device)\n",
        "                    fakez = torch.cat([fakez, c1], dim=1)\n",
        "\n",
        "                fake = self._generator(fakez)\n",
        "                fakeact = self._apply_activate(fake)\n",
        "\n",
        "                if c1 is not None:\n",
        "                    y_fake = discriminator(torch.cat([fakeact, c1], dim=1))\n",
        "                else:\n",
        "                    y_fake = discriminator(fakeact)\n",
        "\n",
        "                if condvec is None:\n",
        "                    cross_entropy = 0\n",
        "                else:\n",
        "                    cross_entropy = self._cond_loss(fake, c1, m1)\n",
        "\n",
        "                loss_g = -torch.mean(y_fake) + cross_entropy\n",
        "\n",
        "                optimizerG.zero_grad(set_to_none=False)\n",
        "                loss_g.backward()\n",
        "                optimizerG.step()\n",
        "\n",
        "            generator_loss = loss_g.detach().cpu()\n",
        "            discriminator_loss = loss_d.detach().cpu()\n",
        "\n",
        "            epoch_loss_df = pd.DataFrame({\n",
        "                'Epoch': [i],\n",
        "                'Generator Loss': [generator_loss],\n",
        "                'Discriminator Loss': [discriminator_loss]\n",
        "            })\n",
        "            if not self.loss_values.empty:\n",
        "                self.loss_values = pd.concat(\n",
        "                    [self.loss_values, epoch_loss_df]\n",
        "                ).reset_index(drop=True)\n",
        "            else:\n",
        "                self.loss_values = epoch_loss_df\n",
        "\n",
        "            if self._verbose:\n",
        "                epoch_iterator.set_description(\n",
        "                    description.format(gen=generator_loss, dis=discriminator_loss)\n",
        "                )\n",
        "\n",
        "    @random_state\n",
        "    def sample(self, _noise, condition_column=None, condition_value=None):\n",
        "        \"\"\"Sample data similar to the training data.\n",
        "\n",
        "        Choosing a condition_column and condition_value will increase the probability of the\n",
        "        discrete condition_value happening in the condition_column.\n",
        "\n",
        "        Args:\n",
        "            n (int):\n",
        "                Number of rows to sample.\n",
        "            condition_column (string):\n",
        "                Name of a discrete column.\n",
        "            condition_value (string):\n",
        "                Name of the category in the condition_column which we wish to increase the\n",
        "                probability of happening.\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray or pandas.DataFrame\n",
        "        \"\"\"\n",
        "        if condition_column is not None and condition_value is not None:\n",
        "            condition_info = self._transformer.convert_column_name_value_to_id(\n",
        "                condition_column, condition_value)\n",
        "            global_condition_vec = self._data_sampler.generate_cond_from_condition_column_info(\n",
        "                condition_info, self._batch_size)\n",
        "        else:\n",
        "            global_condition_vec = None\n",
        "\n",
        "        noise_tensor = torch.from_numpy(_noise).to(self._device)\n",
        "        steps = noise_tensor.shape[0] // self._batch_size + 1\n",
        "        data = []\n",
        "        for i in range(steps):\n",
        "            start_idx = i * self._batch_size\n",
        "            end_idx = (i + 1) * self._batch_size\n",
        "            fakez = noise_tensor[start_idx:end_idx]\n",
        "\n",
        "            if global_condition_vec is not None:\n",
        "                condvec = global_condition_vec.copy()\n",
        "            else:\n",
        "                condvec = self._data_sampler.sample_original_condvec(self._batch_size)\n",
        "\n",
        "            if condvec is None:\n",
        "                pass\n",
        "            else:\n",
        "                c1 = condvec\n",
        "                c1 = torch.from_numpy(c1).to(self._device)\n",
        "                fakez = torch.cat([fakez, c1], dim=1)\n",
        "\n",
        "            fake = self._generator(fakez)\n",
        "            fakeact = self._apply_activate(fake)\n",
        "            data.append(fakeact.detach().cpu().numpy())\n",
        "\n",
        "        data = np.concatenate(data, axis=0)\n",
        "        data = data[:_noise.shape[0]]\n",
        "\n",
        "        trans_data = self._transformer.inverse_transform(data)\n",
        "        trans_data.S1_YIELD = trans_data.S1_YIELD.apply(lambda x: max(x, 0))\n",
        "        trans_data.S2_YIELD = trans_data.S2_YIELD.apply(lambda x: max(x, 0))\n",
        "        trans_data.S3_YIELD = trans_data.S3_YIELD.apply(lambda x: max(x, 0))\n",
        "        trans_data.S4_YIELD = trans_data.S4_YIELD.apply(lambda x: max(x, 0))\n",
        "        return trans_data\n",
        "\n",
        "    def generate(self, noise):\n",
        "      Q1, Q2, Q3, Q4 = 3.3241, 5.1292, 6.4897, 7.1301\n",
        "      gen = self.sample(noise)\n",
        "      gen = gen[(\n",
        "        (gen.S1_W_13 + gen.S1_W_14 + gen.S1_W_15 <= Q1) &\n",
        "        (gen.S2_W_13 + gen.S2_W_14 + gen.S2_W_15 <= Q2) &\n",
        "          (gen.S3_W_13 + gen.S3_W_14 + gen.S3_W_15 <= Q3) &\n",
        "          (gen.S4_W_13 + gen.S4_W_14 + gen.S4_W_15 <= Q4)\n",
        "    )]\n",
        "\n",
        "      while gen.shape[0] < noise.shape[0]:\n",
        "        new = self.sample(noise)\n",
        "        new = new[(\n",
        "            (new.S1_W_13 + new.S1_W_14 + new.S1_W_15 <= Q1) &\n",
        "            (new.S2_W_13 + new.S2_W_14 + new.S2_W_15 <= Q2) &\n",
        "              (new.S3_W_13 + new.S3_W_14 + new.S3_W_15 <= Q3) &\n",
        "              (new.S4_W_13 + new.S4_W_14 + new.S4_W_15 <= Q4)\n",
        "        )]\n",
        "\n",
        "        gen = pd.concat([gen, new], ignore_index=True)\n",
        "      return np.array(gen.iloc[:noise.shape[0], :][[\"S1_YIELD\",\"S2_YIELD\",\"S3_YIELD\",\"S4_YIELD\"]])\n",
        "\n",
        "\n",
        "    def set_device(self, device):\n",
        "        \"\"\"Set the `device` to be used ('GPU' or 'CPU).\"\"\"\n",
        "        self._device = device\n",
        "        if self._generator is not None:\n",
        "            self._generator.to(self._device)"
      ],
      "metadata": {
        "id": "w8uhM4AfmRxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrainement et prediction"
      ],
      "metadata": {
        "id": "Gv2-Bp8ogjVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_col = [col for col in data_interest.columns if \"condition\" not in col]"
      ],
      "metadata": {
        "id": "cDwbLYJ-l8-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ctgan = CTGAN(epochs=10, embedding_dim=50 ,pac = 1)\n",
        "ctgan.fit(real_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUIjqKGozB_x",
        "outputId": "4d757962-0584-4b14-a82e-e37e614d7dfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "swd_distance = ot.sliced.sliced_wasserstein_distance(Yield, output, n_projections=1000)\n",
        "swd_distance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyMNcyT1zgsp",
        "outputId": "caf82066-7bd4-4e87-bbd8-763c2077a7ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49871350655332336"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = np.load(\"/content/output.npy\")"
      ],
      "metadata": {
        "id": "52FPyBJbzDuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_data = data_interest[use_col]\n",
        "for i in range(2) :\n",
        "  epochs = 10\n",
        "  if i%2 == 0:\n",
        "    epochs = 20\n",
        "  ctgan = CTGAN(epochs=10, embedding_dim=50 ,pac = 1)\n",
        "  ctgan.fit(real_data)\n",
        "  swd_distance = ot.sliced.sliced_wasserstein_distance(Yield, ctgan.generate(noise), n_projections=1000)\n",
        "  if swd_distance<0.65:\n",
        "    joblib.dump(ctgan, 'model_' + str(i) + '_' + str(round(swd_distance,2))+ '.pkl')"
      ],
      "metadata": {
        "id": "M89SoCv2gn1R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "edf76666-2473-4cc8-888c-19ae7703901e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-66b18ac7dddb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mctgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCTGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mpac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mctgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mswd_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msliced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msliced_wasserstein_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_projections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mswd_distance\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0.65\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-b94985875c79>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_states\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-5be27b697b0b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, discrete_columns, epochs)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscrete_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         self._data_sampler = DataSampler(\n",
            "\u001b[0;32m<ipython-input-18-741367f0587d>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_data)\u001b[0m\n\u001b[1;32m    172\u001b[0m             )\n\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             column_data_list = self._parallel_transform(\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column_transform_info_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-741367f0587d>\u001b[0m in \u001b[0;36m_parallel_transform\u001b[0;34m(self, raw_data, column_transform_info_list)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mprocesses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1705\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1706\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1708\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"import joblib\n",
        "\n",
        "joblib.dump(model_ensemble, 'model_0_6.pkl')\n",
        "loaded_model_ensemble = joblib.load('model_0_6.pkl')\"\"\"\n",
        "Yiel_col = [\"S1_YIELD\",\"S2_YIELD\",\"S3_YIELD\",\"S4_YIELD\"]"
      ],
      "metadata": {
        "id": "Rr3RA-ADjHuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_data = ctgan.generate(noise)\n",
        "#[Yiel_col] generated_data"
      ],
      "metadata": {
        "id": "daLo7mI9lsrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec90JP3IQqer",
        "outputId": "a2343466-af4a-4b50-cdb4-a9bdf7d30334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "jQ6km4VmZ0JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "swd_distance = ot.sliced.sliced_wasserstein_distance(Yield, generated_data, n_projections=1000)\n",
        "print(\"Sliced Wasserstein Distance :\", swd_distance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9srgYCQXRDg",
        "outputId": "4c4ebed9-824b-4931-beb8-ca86b3986faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sliced Wasserstein Distance : 0.9098755265587818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(ctgan, 'model_0.89.pkl')\n",
        "load_ctgan = joblib.load('model_0_89.pkl')"
      ],
      "metadata": {
        "id": "_6HdW_AaQfT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(generated_data[:,0], bins=200, alpha=0.5, color='red', label='1')\n",
        "plt.hist(generated_data[:,1], bins=200, alpha=0.5, color='green', label='2')\n",
        "plt.hist(generated_data[:,2], bins=200, alpha=0.5, color='blue', label='3')\n",
        "plt.hist(generated_data[:,3], bins=200, alpha=0.5, color='orange', label='4')\n",
        "\n",
        "plt.xlabel('Valeurs')\n",
        "plt.ylabel('Fréquence')\n",
        "plt.title('Distribution de 1, 2, 3, 4')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "oQYF3Z-GYXw2",
        "outputId": "79ed2a79-1611-4b00-f3dd-b740c4e45b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "statistic, p_value = ks_2samp(synthetic_data1.YIELD.to_numpy(), S1_test.YIELD.to_numpy())\n",
        "\n",
        "statistic_ad, critical_values, significance_level = anderson_ksamp([synthetic_data1.YIELD.to_numpy(), S1_test.YIELD.to_numpy()])\n",
        "\n",
        "print(\"Test de Anderson-Darling - Statistique :\", statistic_ad)\n",
        "print(\"Test de Anderson-Darling - Niveaux critiques :\", critical_values)\n",
        "print(\"Test de Anderson-Darling - Niveau de signification :\", significance_level)\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "print(\"Statistique du test de Kolmogorov-Smirnov :\", statistic)\n",
        "print(\"P-value :\", p_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCg18XxFcZy2",
        "outputId": "24b29556-e37e-4bc8-fe25-9f1d8a5009c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test de Anderson-Darling - Statistique : 2214.431421993078\n",
            "Test de Anderson-Darling - Niveaux critiques : [0.325 1.226 1.961 2.718 3.752 4.592 6.546]\n",
            "Test de Anderson-Darling - Niveau de signification : 0.001\n",
            "\n",
            "\n",
            "\n",
            "Statistique du test de Kolmogorov-Smirnov : 0.41377107364685006\n",
            "P-value : 9.096e-321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-faa7f575588c>:3: UserWarning: p-value floored: true value smaller than 0.001\n",
            "  statistic_ad, critical_values, significance_level = anderson_ksamp([synthetic_data.YIELD.to_numpy(), S1_test.YIELD.to_numpy()])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "swd_distance = ot.sliced.sliced_wasserstein_distance(real_data1.YIELD.to_numpy().reshape((real_data1.shape[0],1)), synthetic_data1.YIELD.to_numpy().reshape((synthetic_data1.shape[0],1)))\n",
        "\n",
        "print(\"Sliced Wasserstein Distance :\", swd_distance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFktNUFedZ0k",
        "outputId": "a04bfbef-e7e9-4b81-a12e-e49714dd9944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sliced Wasserstein Distance : 0.4928614273730513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "swd_distance = ot.sliced.sliced_wasserstein_distance(real_data1.YIELD.to_numpy().reshape((real_data1.shape[0],1)), S1_test.YIELD.to_numpy().reshape((S1_test.shape[0],1)))\n",
        "\n",
        "print(\"Sliced Wasserstein Distance :\", swd_distance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMlU1xVicuzA",
        "outputId": "4b1183b9-eb24-4bb2-b1a4-28870d7e40e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sliced Wasserstein Distance : 2.467606534054947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_data1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8LkGSr3r7uf",
        "outputId": "82674687-48a5-42bd-d167-7195e2c78b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}